This one is very much in experimental stages yet, but **V1** (desktop only please!) is looking alright. It's a simple **Nostr** client for long-form content. 

I'm subscribing here to one of the biggest Nostr relays to scalp off as many long-form events as I can find without sacrificing too much on quality. There's a lot of spam floating around for now. But that's the payoff with plugging into global data streams - you'll get a lot of hugely interesting and surprising content, and a bit of mess. 


The relays are remarkably easy to link up! So what's been most challenging about this is working with **complex data structures** that aren't uniform across the dataset. The protocol is **decentralised** and very new, meaning for example that values like titles and tags aren't always labelled correctly and some filtering/searching around is required - plus, it all comes through in Markdown.  

As an aside (that I've left int the MVP because, well, I find it useful): whilst I was developing this client there was a sudden influx of lengthy posts in Portuguese. So I spent a while throwing together a rudimentary translation 'tool' (I've yet to find a decent and free translation API...) that pulls out the first 5,000 charcters and pushes the user to DeepL for them to handle the language detection and translation. It's cumbersome, but it's an OK stopgap solution that gives you a flavour of the breadth and quality of content going up there.

I realise that larger clients are probably dodging the spam problem by avoiding the global feed by default, instead building out user feeds by getting them to follow different accounts. That'd be a good place to expand outwards towards, but I want to play around with **encrypted messaging** first. There's plenty (and counting!) of different NIPs, but this seems like the most interesting area to continue my exploration. 